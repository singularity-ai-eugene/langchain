{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c552cf",
   "metadata": {},
   "source": [
    "# Langchain for Model, Prompt, Reusable Template and Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Packages\n",
    "!pip install -U langchain langchain-community langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Langchain Version\n",
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "# 1. Setup your key\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"XXX\"\n",
    "# 2. Import the model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "# 3. Initialize the model \n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "# 4. Invoke the model\n",
    "result = llm.invoke(\"What is 1+1\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0333dc",
   "metadata": {},
   "source": [
    "## Basic template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b097e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "I am fuming over the spoiled machine\"\"\"\n",
    "\n",
    "style = \"\"\"Pirate English\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Translate the text \\\n",
    "    that is delimited by triple backticks\n",
    "    into a style thst is {style}.\n",
    "    text: ```{customer_email}```\n",
    "    \"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33875bf2",
   "metadata": {},
   "source": [
    "## Reuse template with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "    that is delimited by triple backticks\n",
    "    into a style thst is {style}.\n",
    "    text: ```{text}```\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9157054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English in a calm \\\n",
    "                    and respectful tone\"\"\"\n",
    "\n",
    "customer_email = \"\"\" \\\n",
    "    I am fuming over the spoiled machine. \\\n",
    "    Why did it breakdown in less than 3 months? \\\n",
    "    Where was this manufactured in? \\\n",
    "    What lousy parts were used?\"\"\"\n",
    "\n",
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33327b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))\n",
    "print(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(customer_messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb9806",
   "metadata": {},
   "source": [
    "## Defining Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119cbc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a03ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc793324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 1 = 2\n",
      "```json\n",
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\n",
      "    \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "# 1. Setup your key (Using the one you provided)\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"XXX\"\n",
    "\n",
    "# 2. Import the model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# 3. Initialize the model (e.g., gemini-1.5-pro or gemini-pro)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "# 4. Invoke the model\n",
    "result = llm.invoke(\"What is 1+1\")\n",
    "print(result.content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "\n",
    "messages = prompt_template.format_messages(\n",
    "                    text=customer_review\n",
    "                    )\n",
    "\n",
    "result = llm.invoke(messages, temperature=0.0)\n",
    "print (result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b970b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gift=True delivery_days=2 price_value=[\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "True\n",
      "2\n",
      "[\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# 1. Standard Pydantic definition\n",
    "class ReviewAnalysis(BaseModel):\n",
    "    gift: bool = Field(description=\"Was it a gift? True/False.\")\n",
    "    delivery_days: int = Field(description=\"Days to arrive, -1 if unknown.\")\n",
    "    price_value: List[str] = Field(description=\"Sentences about price.\")\n",
    "\n",
    "# 2. Modern 1.2.6 Implementation\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "# This binds the schema to the model natively\n",
    "structured_llm = llm.with_structured_output(ReviewAnalysis)\n",
    "\n",
    "# 3. Execution (The output is already a Python object!)\n",
    "result = structured_llm.invoke(messages)\n",
    "\n",
    "print (result)\n",
    "print (result.gift)\n",
    "print (result.delivery_days)\n",
    "print (result.price_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2438eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\n",
      "    \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Convert the Pydantic object to a standard Python dictionary and to JSON\n",
    "formatted_result = result.model_dump()\n",
    "\n",
    "print(json.dumps(formatted_result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
